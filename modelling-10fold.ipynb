{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5ffd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:40:45.446484: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-26 12:40:45.485242: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-26 12:40:45.485941: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 12:40:46.090521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from modellib.attention import Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3c7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./logs/data/dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8be7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATT(input_shape):\n",
    "    inp=tf.keras.layers.Input(input_shape)\n",
    "    net=Attention((None,*input_shape))(inp)\n",
    "    out=tf.keras.layers.Dense(units=256,activation=\"relu\")(net)\n",
    "    att_model=tf.keras.Model(inputs=inp,outputs=out,name=\"ATT\")\n",
    "    return att_model\n",
    "\n",
    "def CNN(input_shape):\n",
    "    cnn_model=\\\n",
    "    tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64,(5,5),(2,2),\"same\",activation=\"relu\",input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),(2,2),\"same\",activation=\"relu\"),\n",
    "        tf.keras.layers.Conv2D(256,(3,3),(2,2),\"same\",activation=\"relu\"),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    ],name='CNN')\n",
    "    return cnn_model\n",
    "\n",
    "def ANN(input_shape):\n",
    "    ann_model=\\\n",
    "    tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=256,activation=\"relu\",input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(units=64,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(units=1,activation=\"linear\")\n",
    "    ],name='ANN')\n",
    "    return ann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209346c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0766074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fused_model():\n",
    "    X_seq=tf.keras.layers.Input(shape=(10,21))\n",
    "    X_img=tf.keras.layers.Input(shape=(64,64,3))\n",
    "\n",
    "    cnn=CNN((64,64,3))\n",
    "    att=ATT((10,21))\n",
    "    ann=ANN((512,))\n",
    "\n",
    "    cnn_emb=cnn(X_img)\n",
    "    att_emb=att(X_seq)\n",
    "    net=tf.concat([cnn_emb,att_emb],axis=1)\n",
    "    out=ann(net)\n",
    "\n",
    "    fused_model=tf.keras.Model(inputs=[X_seq,X_img],outputs=out,name='FUSED')\n",
    "    fused_model.compile(loss=\"mse\",optimizer=\"adam\",metrics=[\"mae\",\"mse\"])\n",
    "    return fused_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d03567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smax=np.max(dataset[\"seq\"],axis=0)\n",
    "smin=np.min(dataset[\"seq\"],axis=0)\n",
    "seq_scaled=np.float32((dataset[\"seq\"]-smin)/(smax-smin))\n",
    "img_scaled=np.float32(dataset['img']/255.)\n",
    "\n",
    "speed=np.float32(dataset[\"spd\"].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177670f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On split: 7\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:40:47.961077: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 367804416 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 14s 110ms/step - loss: 336.6964 - mae: 13.3334 - mse: 336.6964 - val_loss: 161.2447 - val_mae: 9.2098 - val_mse: 161.2447\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 143.1108 - mae: 8.9395 - mse: 143.1108 - val_loss: 113.7206 - val_mae: 8.1069 - val_mse: 113.7206\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 18s 155ms/step - loss: 112.8244 - mae: 7.8521 - mse: 112.8244 - val_loss: 89.1658 - val_mae: 7.0737 - val_mse: 89.1658\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 17s 149ms/step - loss: 93.2539 - mae: 7.0961 - mse: 93.2539 - val_loss: 73.0971 - val_mae: 6.5061 - val_mse: 73.0971\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 15s 124ms/step - loss: 74.1185 - mae: 6.3353 - mse: 74.1185 - val_loss: 56.0737 - val_mae: 5.4856 - val_mse: 56.0737\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 14s 115ms/step - loss: 58.1680 - mae: 5.6233 - mse: 58.1680 - val_loss: 43.5657 - val_mae: 4.8844 - val_mse: 43.5657\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 47.6618 - mae: 5.1081 - mse: 47.6618 - val_loss: 37.8786 - val_mae: 4.5750 - val_mse: 37.8786\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 39.3672 - mae: 4.5847 - mse: 39.3672 - val_loss: 33.4288 - val_mae: 4.2956 - val_mse: 33.4288\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 36.2618 - mae: 4.3877 - mse: 36.2618 - val_loss: 30.4522 - val_mae: 4.0720 - val_mse: 30.4522\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 33.2915 - mae: 4.1817 - mse: 33.2915 - val_loss: 34.6918 - val_mae: 4.4860 - val_mse: 34.6918\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 31.9863 - mae: 4.1179 - mse: 31.9863 - val_loss: 28.3386 - val_mae: 4.0129 - val_mse: 28.3386\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 30.5526 - mae: 4.0124 - mse: 30.5526 - val_loss: 31.5991 - val_mae: 4.2719 - val_mse: 31.5991\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 28.8455 - mae: 3.8708 - mse: 28.8455 - val_loss: 29.2424 - val_mae: 4.1995 - val_mse: 29.2424\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 28.4231 - mae: 3.8768 - mse: 28.4231 - val_loss: 28.0253 - val_mae: 3.9769 - val_mse: 28.0253\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 27.1977 - mae: 3.7598 - mse: 27.1977 - val_loss: 23.2524 - val_mae: 3.5546 - val_mse: 23.2524\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 26.3568 - mae: 3.7173 - mse: 26.3568 - val_loss: 23.9422 - val_mae: 3.6723 - val_mse: 23.9422\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 25.3831 - mae: 3.6405 - mse: 25.3831 - val_loss: 24.4265 - val_mae: 3.7011 - val_mse: 24.4265\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 24.4722 - mae: 3.5783 - mse: 24.4722 - val_loss: 21.6849 - val_mae: 3.5142 - val_mse: 21.6849\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 22.9984 - mae: 3.4373 - mse: 22.9984 - val_loss: 21.9496 - val_mae: 3.4912 - val_mse: 21.9496\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 22.8825 - mae: 3.4385 - mse: 22.8825 - val_loss: 22.6915 - val_mae: 3.5118 - val_mse: 22.6915\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 22.6602 - mae: 3.4120 - mse: 22.6602 - val_loss: 20.5274 - val_mae: 3.3214 - val_mse: 20.5274\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 21.2391 - mae: 3.2935 - mse: 21.2391 - val_loss: 19.7010 - val_mae: 3.2735 - val_mse: 19.7010\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 20.9381 - mae: 3.2904 - mse: 20.9381 - val_loss: 20.1402 - val_mae: 3.2784 - val_mse: 20.1402\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 20.8614 - mae: 3.2914 - mse: 20.8614 - val_loss: 23.0088 - val_mae: 3.6641 - val_mse: 23.0088\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 20.5905 - mae: 3.2583 - mse: 20.5905 - val_loss: 20.1648 - val_mae: 3.2650 - val_mse: 20.1648\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 19.4499 - mae: 3.1383 - mse: 19.4499 - val_loss: 19.5325 - val_mae: 3.2548 - val_mse: 19.5325\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 20.6480 - mae: 3.2932 - mse: 20.6480 - val_loss: 18.8964 - val_mae: 3.1672 - val_mse: 18.8964\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 19.3210 - mae: 3.1519 - mse: 19.3210 - val_loss: 19.0407 - val_mae: 3.2000 - val_mse: 19.0407\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 19.1214 - mae: 3.1574 - mse: 19.1214 - val_loss: 23.8007 - val_mae: 3.6162 - val_mse: 23.8007\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 20.5114 - mae: 3.3030 - mse: 20.5114 - val_loss: 21.2539 - val_mae: 3.5200 - val_mse: 21.2539\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 18.0110 - mae: 3.0555 - mse: 18.0110 - val_loss: 18.6976 - val_mae: 3.1926 - val_mse: 18.6976\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 17.3594 - mae: 3.0020 - mse: 17.3594 - val_loss: 18.8411 - val_mae: 3.2136 - val_mse: 18.8411\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 17.1199 - mae: 2.9663 - mse: 17.1199 - val_loss: 22.4242 - val_mae: 3.5334 - val_mse: 22.4242\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 17.3035 - mae: 3.0185 - mse: 17.3035 - val_loss: 22.7860 - val_mae: 3.5954 - val_mse: 22.7860\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 17.2600 - mae: 3.0400 - mse: 17.2600 - val_loss: 17.6838 - val_mae: 3.0606 - val_mse: 17.6838\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 15.7486 - mae: 2.8525 - mse: 15.7486 - val_loss: 19.8816 - val_mae: 3.2862 - val_mse: 19.8816\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 16.0160 - mae: 2.9102 - mse: 16.0160 - val_loss: 25.8310 - val_mae: 3.9767 - val_mse: 25.8310\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 15.8126 - mae: 2.9017 - mse: 15.8126 - val_loss: 18.6099 - val_mae: 3.1811 - val_mse: 18.6099\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 15.5167 - mae: 2.8779 - mse: 15.5167 - val_loss: 17.3507 - val_mae: 3.0338 - val_mse: 17.3507\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 15.4378 - mae: 2.8693 - mse: 15.4378 - val_loss: 20.2364 - val_mae: 3.3138 - val_mse: 20.2364\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 14.9511 - mae: 2.8090 - mse: 14.9511 - val_loss: 17.7395 - val_mae: 3.0803 - val_mse: 17.7395\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 14.3243 - mae: 2.7635 - mse: 14.3243 - val_loss: 18.5069 - val_mae: 3.1726 - val_mse: 18.5069\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 13.9370 - mae: 2.7310 - mse: 13.9370 - val_loss: 18.1388 - val_mae: 3.1251 - val_mse: 18.1388\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 14.2998 - mae: 2.7750 - mse: 14.2998 - val_loss: 18.5932 - val_mae: 3.1847 - val_mse: 18.5932\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 14.1493 - mae: 2.7581 - mse: 14.1493 - val_loss: 17.0579 - val_mae: 2.9991 - val_mse: 17.0579\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 12.8453 - mae: 2.6307 - mse: 12.8453 - val_loss: 17.0535 - val_mae: 3.0041 - val_mse: 17.0535\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 13.1951 - mae: 2.6772 - mse: 13.1951 - val_loss: 16.9566 - val_mae: 3.0069 - val_mse: 16.9566\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 13.5353 - mae: 2.7268 - mse: 13.5353 - val_loss: 17.1824 - val_mae: 3.0415 - val_mse: 17.1824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 12.0819 - mae: 2.5530 - mse: 12.0819 - val_loss: 17.7289 - val_mae: 3.0853 - val_mse: 17.7289\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 12.7005 - mae: 2.6331 - mse: 12.7005 - val_loss: 17.8081 - val_mae: 3.0725 - val_mse: 17.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:51:29.842770: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 459767808 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On split: 8\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:51:33.975703: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 367804416 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 14s 107ms/step - loss: 355.9223 - mae: 13.7084 - mse: 355.9223 - val_loss: 149.4263 - val_mae: 9.1184 - val_mse: 149.4263\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 149.2846 - mae: 9.1294 - mse: 149.2846 - val_loss: 106.7474 - val_mae: 7.9048 - val_mse: 106.7474\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 119.9203 - mae: 8.1032 - mse: 119.9203 - val_loss: 85.7694 - val_mae: 6.9613 - val_mse: 85.7694\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 102.5770 - mae: 7.4377 - mse: 102.5770 - val_loss: 74.6226 - val_mae: 6.6055 - val_mse: 74.6226\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 14s 115ms/step - loss: 84.3231 - mae: 6.7485 - mse: 84.3231 - val_loss: 57.9939 - val_mae: 5.5397 - val_mse: 57.9939\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 67.0570 - mae: 6.0128 - mse: 67.0570 - val_loss: 44.3009 - val_mae: 5.0053 - val_mse: 44.3009\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 52.2551 - mae: 5.3210 - mse: 52.2551 - val_loss: 36.8003 - val_mae: 4.4440 - val_mse: 36.8003\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 40.4397 - mae: 4.6424 - mse: 40.4397 - val_loss: 31.1163 - val_mae: 4.1434 - val_mse: 31.1163\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 35.9410 - mae: 4.3645 - mse: 35.9410 - val_loss: 27.2696 - val_mae: 3.8854 - val_mse: 27.2696\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 33.0270 - mae: 4.1672 - mse: 33.0270 - val_loss: 31.9301 - val_mae: 4.2961 - val_mse: 31.9301\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 31.5360 - mae: 4.0982 - mse: 31.5360 - val_loss: 25.2423 - val_mae: 3.7813 - val_mse: 25.2423\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 30.0829 - mae: 3.9881 - mse: 30.0829 - val_loss: 29.3577 - val_mae: 4.1599 - val_mse: 29.3577\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 28.4910 - mae: 3.8645 - mse: 28.4910 - val_loss: 24.6311 - val_mae: 3.8537 - val_mse: 24.6311\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 27.1565 - mae: 3.7819 - mse: 27.1565 - val_loss: 23.9570 - val_mae: 3.6353 - val_mse: 23.9570\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 26.3294 - mae: 3.6954 - mse: 26.3294 - val_loss: 21.1497 - val_mae: 3.3528 - val_mse: 21.1497\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 25.3445 - mae: 3.6469 - mse: 25.3445 - val_loss: 20.3654 - val_mae: 3.4400 - val_mse: 20.3654\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 24.4295 - mae: 3.5717 - mse: 24.4295 - val_loss: 20.8511 - val_mae: 3.3933 - val_mse: 20.8511\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 23.5758 - mae: 3.5030 - mse: 23.5758 - val_loss: 17.7411 - val_mae: 3.1832 - val_mse: 17.7411\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 22.0148 - mae: 3.3511 - mse: 22.0148 - val_loss: 17.3151 - val_mae: 3.0916 - val_mse: 17.3151\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 21.4899 - mae: 3.3299 - mse: 21.4899 - val_loss: 19.3214 - val_mae: 3.2520 - val_mse: 19.3214\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 20.9914 - mae: 3.2782 - mse: 20.9914 - val_loss: 17.3545 - val_mae: 3.0714 - val_mse: 17.3545\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 20.1313 - mae: 3.2040 - mse: 20.1313 - val_loss: 16.3472 - val_mae: 2.9992 - val_mse: 16.3472\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 19.6237 - mae: 3.1766 - mse: 19.6237 - val_loss: 16.4346 - val_mae: 3.0122 - val_mse: 16.4346\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 19.3798 - mae: 3.1646 - mse: 19.3798 - val_loss: 18.7652 - val_mae: 3.3300 - val_mse: 18.7652\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 19.2022 - mae: 3.1448 - mse: 19.2022 - val_loss: 15.8986 - val_mae: 2.9009 - val_mse: 15.8986\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 17.9064 - mae: 3.0207 - mse: 17.9064 - val_loss: 15.0158 - val_mae: 2.8807 - val_mse: 15.0158\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 18.7528 - mae: 3.1297 - mse: 18.7528 - val_loss: 14.7215 - val_mae: 2.7927 - val_mse: 14.7215\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 17.3494 - mae: 2.9796 - mse: 17.3494 - val_loss: 14.3427 - val_mae: 2.7501 - val_mse: 14.3427\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 17.6544 - mae: 3.0344 - mse: 17.6544 - val_loss: 18.8395 - val_mae: 3.2400 - val_mse: 18.8395\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 17.5128 - mae: 3.0360 - mse: 17.5128 - val_loss: 17.6943 - val_mae: 3.2347 - val_mse: 17.6943\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 16.1062 - mae: 2.8819 - mse: 16.1062 - val_loss: 14.3577 - val_mae: 2.7940 - val_mse: 14.3577\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 15.6063 - mae: 2.8684 - mse: 15.6063 - val_loss: 14.8571 - val_mae: 2.8829 - val_mse: 14.8571\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 15.5596 - mae: 2.8381 - mse: 15.5596 - val_loss: 18.3268 - val_mae: 3.2814 - val_mse: 18.3268\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 15.3868 - mae: 2.8544 - mse: 15.3868 - val_loss: 17.6805 - val_mae: 3.1994 - val_mse: 17.6805\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 15.6313 - mae: 2.8920 - mse: 15.6313 - val_loss: 13.6742 - val_mae: 2.7593 - val_mse: 13.6742\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 13.9284 - mae: 2.7017 - mse: 13.9284 - val_loss: 16.6336 - val_mae: 3.1141 - val_mse: 16.6336\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 13.8459 - mae: 2.7118 - mse: 13.8459 - val_loss: 20.2543 - val_mae: 3.5410 - val_mse: 20.2543\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 14.2296 - mae: 2.7499 - mse: 14.2296 - val_loss: 15.0198 - val_mae: 2.8929 - val_mse: 15.0198\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 13.3780 - mae: 2.6677 - mse: 13.3780 - val_loss: 13.5632 - val_mae: 2.7106 - val_mse: 13.5632\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 14.0952 - mae: 2.7541 - mse: 14.0952 - val_loss: 16.0693 - val_mae: 3.0471 - val_mse: 16.0693\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 13.5190 - mae: 2.6986 - mse: 13.5190 - val_loss: 13.9852 - val_mae: 2.7777 - val_mse: 13.9852\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 12.2267 - mae: 2.5575 - mse: 12.2267 - val_loss: 18.7619 - val_mae: 3.3596 - val_mse: 18.7619\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 12.5249 - mae: 2.5975 - mse: 12.5249 - val_loss: 14.3127 - val_mae: 2.8208 - val_mse: 14.3127\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 12.4476 - mae: 2.6016 - mse: 12.4476 - val_loss: 14.8911 - val_mae: 2.9092 - val_mse: 14.8911\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 12.4215 - mae: 2.6019 - mse: 12.4215 - val_loss: 13.1293 - val_mae: 2.6759 - val_mse: 13.1293\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 11.0008 - mae: 2.4330 - mse: 11.0008 - val_loss: 13.4136 - val_mae: 2.7072 - val_mse: 13.4136\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 10.9074 - mae: 2.4308 - mse: 10.9074 - val_loss: 13.9836 - val_mae: 2.8004 - val_mse: 13.9836\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 11.1983 - mae: 2.4791 - mse: 11.1983 - val_loss: 13.6969 - val_mae: 2.7542 - val_mse: 13.6969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 9.9523 - mae: 2.3216 - mse: 9.9523 - val_loss: 13.9429 - val_mae: 2.7858 - val_mse: 13.9429\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 9.9623 - mae: 2.3257 - mse: 9.9623 - val_loss: 14.0453 - val_mae: 2.7703 - val_mse: 14.0453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 13:01:59.061629: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 459767808 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On split: 9\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 13:02:03.138915: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 367804416 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 14s 108ms/step - loss: 355.8886 - mae: 13.7474 - mse: 355.8886 - val_loss: 156.8026 - val_mae: 9.2058 - val_mse: 156.8026\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 150.8930 - mae: 9.1836 - mse: 150.8930 - val_loss: 104.8974 - val_mae: 7.7875 - val_mse: 104.8974\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 118.1704 - mae: 8.0523 - mse: 118.1704 - val_loss: 88.2068 - val_mae: 6.9878 - val_mse: 88.2068\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 98.6758 - mae: 7.2942 - mse: 98.6758 - val_loss: 73.8989 - val_mae: 6.4197 - val_mse: 73.8989\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 80.2734 - mae: 6.5745 - mse: 80.2734 - val_loss: 58.1169 - val_mae: 5.4312 - val_mse: 58.1169\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 62.9221 - mae: 5.8210 - mse: 62.9221 - val_loss: 45.8391 - val_mae: 4.9210 - val_mse: 45.8391\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 50.5779 - mae: 5.2271 - mse: 50.5779 - val_loss: 37.8899 - val_mae: 4.4496 - val_mse: 37.8899\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 40.9051 - mae: 4.6679 - mse: 40.9051 - val_loss: 34.7337 - val_mae: 4.3495 - val_mse: 34.7337\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 37.5590 - mae: 4.4731 - mse: 37.5590 - val_loss: 31.4186 - val_mae: 4.1039 - val_mse: 31.4186\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 34.4960 - mae: 4.2842 - mse: 34.4960 - val_loss: 34.7407 - val_mae: 4.4854 - val_mse: 34.7407\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 32.3835 - mae: 4.1572 - mse: 32.3835 - val_loss: 29.8909 - val_mae: 4.0827 - val_mse: 29.8909\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 31.0552 - mae: 4.0755 - mse: 31.0552 - val_loss: 33.4733 - val_mae: 4.4380 - val_mse: 33.4733\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 29.1954 - mae: 3.9206 - mse: 29.1954 - val_loss: 29.9357 - val_mae: 4.1349 - val_mse: 29.9357\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 28.1957 - mae: 3.8777 - mse: 28.1957 - val_loss: 26.2675 - val_mae: 3.7591 - val_mse: 26.2675\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 27.7122 - mae: 3.8193 - mse: 27.7122 - val_loss: 24.6397 - val_mae: 3.6133 - val_mse: 24.6397\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 13s 109ms/step - loss: 26.7840 - mae: 3.7664 - mse: 26.7840 - val_loss: 25.2265 - val_mae: 3.6644 - val_mse: 25.2265\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 25.9254 - mae: 3.6943 - mse: 25.9254 - val_loss: 26.4443 - val_mae: 3.8391 - val_mse: 26.4443\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 25.1513 - mae: 3.6361 - mse: 25.1513 - val_loss: 21.2673 - val_mae: 3.3249 - val_mse: 21.2673\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 23.5349 - mae: 3.4868 - mse: 23.5349 - val_loss: 21.3233 - val_mae: 3.3057 - val_mse: 21.3233\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 23.0985 - mae: 3.4403 - mse: 23.0985 - val_loss: 23.1437 - val_mae: 3.5547 - val_mse: 23.1437\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 22.6830 - mae: 3.4029 - mse: 22.6830 - val_loss: 21.0702 - val_mae: 3.3624 - val_mse: 21.0702\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 21.8868 - mae: 3.3437 - mse: 21.8868 - val_loss: 19.9853 - val_mae: 3.2580 - val_mse: 19.9853\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 21.4134 - mae: 3.3095 - mse: 21.4134 - val_loss: 19.3825 - val_mae: 3.1575 - val_mse: 19.3825\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 21.0555 - mae: 3.2838 - mse: 21.0555 - val_loss: 21.3400 - val_mae: 3.3878 - val_mse: 21.3400\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 21.1270 - mae: 3.2864 - mse: 21.1270 - val_loss: 19.6105 - val_mae: 3.2058 - val_mse: 19.6105\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 20.1454 - mae: 3.1931 - mse: 20.1454 - val_loss: 18.7764 - val_mae: 3.1294 - val_mse: 18.7764\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 21.0873 - mae: 3.3051 - mse: 21.0873 - val_loss: 17.6758 - val_mae: 3.0180 - val_mse: 17.6758\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 19.6939 - mae: 3.1702 - mse: 19.6939 - val_loss: 17.7794 - val_mae: 3.0285 - val_mse: 17.7794\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 19.8497 - mae: 3.2005 - mse: 19.8497 - val_loss: 23.1414 - val_mae: 3.5530 - val_mse: 23.1414\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 19.8569 - mae: 3.2156 - mse: 19.8569 - val_loss: 20.6812 - val_mae: 3.4082 - val_mse: 20.6812\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 12s 106ms/step - loss: 18.4930 - mae: 3.0932 - mse: 18.4930 - val_loss: 17.6611 - val_mae: 3.0333 - val_mse: 17.6611\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 18.2432 - mae: 3.0698 - mse: 18.2432 - val_loss: 17.8433 - val_mae: 3.0585 - val_mse: 17.8433\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 17.6845 - mae: 3.0121 - mse: 17.6845 - val_loss: 22.6799 - val_mae: 3.6030 - val_mse: 22.6799\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 17.6183 - mae: 3.0065 - mse: 17.6183 - val_loss: 22.1803 - val_mae: 3.5886 - val_mse: 22.1803\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 18.0923 - mae: 3.0886 - mse: 18.0923 - val_loss: 17.3433 - val_mae: 2.9929 - val_mse: 17.3433\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 16.6411 - mae: 2.9277 - mse: 16.6411 - val_loss: 19.8805 - val_mae: 3.2928 - val_mse: 19.8805\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 16.3747 - mae: 2.9257 - mse: 16.3747 - val_loss: 23.5106 - val_mae: 3.7458 - val_mse: 23.5106\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 16.3803 - mae: 2.9328 - mse: 16.3803 - val_loss: 17.3808 - val_mae: 3.0119 - val_mse: 17.3808\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 15.7464 - mae: 2.8655 - mse: 15.7464 - val_loss: 16.5461 - val_mae: 2.9132 - val_mse: 16.5461\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 15.6187 - mae: 2.8661 - mse: 15.6187 - val_loss: 22.2012 - val_mae: 3.5992 - val_mse: 22.2012\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 15.4169 - mae: 2.8434 - mse: 15.4169 - val_loss: 16.4927 - val_mae: 2.9356 - val_mse: 16.4927\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 14.6976 - mae: 2.8003 - mse: 14.6976 - val_loss: 21.7333 - val_mae: 3.5675 - val_mse: 21.7333\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 14.7391 - mae: 2.7871 - mse: 14.7391 - val_loss: 18.6018 - val_mae: 3.2101 - val_mse: 18.6018\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 15.0641 - mae: 2.8381 - mse: 15.0641 - val_loss: 17.4513 - val_mae: 3.0708 - val_mse: 17.4513\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 13s 108ms/step - loss: 14.4823 - mae: 2.7900 - mse: 14.4823 - val_loss: 16.9240 - val_mae: 2.9779 - val_mse: 16.9240\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 13.1223 - mae: 2.6538 - mse: 13.1223 - val_loss: 16.8927 - val_mae: 2.9785 - val_mse: 16.8927\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 13.3963 - mae: 2.6780 - mse: 13.3963 - val_loss: 16.4177 - val_mae: 2.9181 - val_mse: 16.4177\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 13s 107ms/step - loss: 13.2806 - mae: 2.6754 - mse: 13.2806 - val_loss: 16.7489 - val_mae: 2.9812 - val_mse: 16.7489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 11.9345 - mae: 2.5147 - mse: 11.9345 - val_loss: 17.9528 - val_mae: 3.1128 - val_mse: 17.9528\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 12s 107ms/step - loss: 12.0593 - mae: 2.5621 - mse: 12.0593 - val_loss: 17.3295 - val_mae: 3.0432 - val_mse: 17.3295\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "fold=KFold(n_splits=10)\n",
    "for split,(train_idx,test_idx) in enumerate(fold.split(np.arange(speed.shape[0]))):\n",
    "    print(f\"On split: {split}\")\n",
    "    seq_train=seq_scaled[train_idx]\n",
    "    img_train=img_scaled[train_idx]\n",
    "    speed_train=speed[train_idx]\n",
    "    seq_test=seq_scaled[test_idx]\n",
    "    img_test=img_scaled[test_idx]\n",
    "    speed_test=speed[test_idx]\n",
    "\n",
    "    #Training\n",
    "    fused_model=get_fused_model()\n",
    "    best_save=tf.keras.callbacks.ModelCheckpoint(filepath=f\"./logs/model/tr_{split}.h5\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_mae',mode='max',\n",
    "                                                 save_best_only=True)\n",
    "    \n",
    "    training=fused_model.fit(x=[seq_train,img_train],y=speed_train,batch_size=64,epochs=50,\n",
    "                             validation_split=0.2,callbacks=[best_save])\n",
    "    #Evaluate\n",
    "    pred=fused_model.predict([seq_train,img_train],verbose=0)\n",
    "    mae_train=mean_absolute_error(speed_train,pred)\n",
    "    mse_train=mean_squared_error(speed_train,pred)\n",
    "    r2_train=r2_score(speed_train,pred)\n",
    "\n",
    "    pred=fused_model.predict([seq_test,img_test],verbose=0)\n",
    "    mae_test=mean_absolute_error(speed_test,pred)\n",
    "    mse_test=mean_squared_error(speed_test,pred)\n",
    "    r2_test=r2_score(speed_test,pred)\n",
    "\n",
    "    res={'spt':split,'mae_train':mae_train,'mse_train':mse_train,'r2_train':r2_train,\n",
    "     'mae_test':mae_test,'mse_test':mse_test,'r2_test':r2_test}\n",
    "    l.append(res)\n",
    "    \n",
    "    pd.DataFrame(l).to_csv('./Output/res_10fold2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b98abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
