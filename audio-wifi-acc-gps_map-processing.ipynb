{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from library.readingData import read_data_from_folder\n",
    "from library.other_processing import get_processed_rows_for\n",
    "from library.constants import over_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import library.audio_processing\n",
    "import library.other_processing\n",
    "import library.map_processing\n",
    "importlib.reload(library.audio_processing)\n",
    "importlib.reload(library.other_processing)\n",
    "importlib.reload(library.map_processing)\n",
    "from library.map_processing import MapFeatExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder=\"/Users/ajay/Desktop/MTP/bikesense/Data/Two_W\"\n",
    "target_folder=\"/Users/ajay/Desktop/MTP/bikesense/Trails/TW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPERS\n",
    "\n",
    "mfe=MapFeatExtractor(data_folder) #map feature extractor\n",
    "\n",
    "folders=glob.glob(data_folder+\"/*/*\") #all folders in the data_folder\n",
    "\n",
    "#name output folders in this manner\n",
    "def get_folder_name(folder_number,src_folder_path):\n",
    "    return \"_\".join(src_folder_path.split(\"/\")[-3:])+f\"_{folder_number}\"\n",
    "\n",
    "#processing sensor & map data from a Lambda meter long patch\n",
    "def whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,Lambda=100): #default 100 meter\n",
    "    p_data, gps_points=get_processed_rows_for(data,Lambda) #processing sensor_data\n",
    "    return mfe.add_map_features_to_processed_data(p_data, gps_points, img_dir, Lambda) #adding map data to it\n",
    "\n",
    "#check if any data file is not saved for a perticular folder\n",
    "def check_if_data_need_to_be_process(folder_name):\n",
    "    status=\\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_100.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_200.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_300.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_400.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_500.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_1000.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_1500.csv\")) or \\\n",
    "    (not os.path.exists(f\"./{folder_name}/DATA_2000.csv\"))\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two_W_2019_DATA_18_13_26_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/168 [01:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/PIL/ImageFile.py:515\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m     fh \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mfileno()\n\u001b[1;32m    516\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,\u001b[39m1000\u001b[39m)\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m{\u001b[39;00mfolder_name\u001b[39m}\u001b[39;00m\u001b[39m/DATA_1000.csv\u001b[39m\u001b[39m\"\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m     whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,\u001b[39m1500\u001b[39m)\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m{\u001b[39;00mfolder_name\u001b[39m}\u001b[39;00m\u001b[39m/DATA_1500.csv\u001b[39m\u001b[39m\"\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m     whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,\u001b[39m2000\u001b[39;49m)\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m{\u001b[39;00mfolder_name\u001b[39m}\u001b[39;00m\u001b[39m/DATA_2000.csv\u001b[39m\u001b[39m\"\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     26\u001b[0m folder_number\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[129], line 14\u001b[0m, in \u001b[0;36mwhole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map\u001b[0;34m(data, img_dir, Lambda)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map\u001b[39m(data,img_dir,Lambda\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m): \u001b[39m#default 100 meter\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     p_data, gps_points\u001b[39m=\u001b[39mget_processed_rows_for(data,Lambda) \u001b[39m#processing sensor_data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mreturn\u001b[39;00m mfe\u001b[39m.\u001b[39;49madd_map_features_to_processed_data(p_data, gps_points, img_dir, Lambda)\n",
      "File \u001b[0;32m~/Desktop/MTP/bikesense/library/map_processing.py:205\u001b[0m, in \u001b[0;36mMapFeatExtractor.add_map_features_to_processed_data\u001b[0;34m(self, p_data, gps_data_patches, img_dir, data_is_processed_for)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mfor\u001b[39;00m lat,long \u001b[39min\u001b[39;00m lat_longs\u001b[39m.\u001b[39mvalues:\n\u001b[1;32m    204\u001b[0m     filepath \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mimg_dir\u001b[39m}\u001b[39;00m\u001b[39m/img_\u001b[39m\u001b[39m{\u001b[39;00mdata_is_processed_for\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 205\u001b[0m     map_feats\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_features_from_circular_patch_save_patch(lat,long,filepath,data_is_processed_for))\n\u001b[1;32m    206\u001b[0m     filepath \u001b[39m=\u001b[39m filepath\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39mbikesense\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    207\u001b[0m     filepaths\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/MTP/bikesense/library/map_processing.py:195\u001b[0m, in \u001b[0;36mMapFeatExtractor.get_features_from_circular_patch_save_patch\u001b[0;34m(self, lat, long, filepath, diameter)\u001b[0m\n\u001b[1;32m    192\u001b[0m total_area\u001b[39m=\u001b[39mcir_channel[:,:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msum() \u001b[39m#taking only one channel\u001b[39;00m\n\u001b[1;32m    194\u001b[0m patch_img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(patch, \u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 195\u001b[0m patch_img\u001b[39m.\u001b[39;49msave(filepath)\n\u001b[1;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m get_poi_feat(patch,total_area)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/PIL/Image.py:2432\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2431\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2432\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[1;32m   2433\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   2434\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/PIL/PngImagePlugin.py:1407\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[1;32m   1406\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1407\u001b[0m     ImageFile\u001b[39m.\u001b[39;49m_save(im, _idat(fp, chunk), [(\u001b[39m\"\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m\"\u001b[39;49m, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39;49m im\u001b[39m.\u001b[39;49msize, \u001b[39m0\u001b[39;49m, rawmode)])\n\u001b[1;32m   1409\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[1;32m   1410\u001b[0m     \u001b[39mfor\u001b[39;00m info_chunk \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mchunks:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/PIL/ImageFile.py:519\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    518\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 519\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[39mNone\u001b[39;49;00m, exc)\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    521\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/PIL/ImageFile.py:538\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m exc:\n\u001b[1;32m    536\u001b[0m     \u001b[39m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m         errcode, data \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mencode(bufsize)[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    539\u001b[0m         fp\u001b[39m.\u001b[39mwrite(data)\n\u001b[1;32m    540\u001b[0m         \u001b[39mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(target_folder)\n",
    "\n",
    "folder_number=0\n",
    "\n",
    "for folder_path in tqdm(folders):\n",
    "    folder_name=get_folder_name(folder_number,folder_path)\n",
    "    if(check_if_data_need_to_be_process(folder_name) or over_write):\n",
    "        #either file doesnot exist or over-write is true then it will process!\n",
    "        os.makedirs(folder_name,exist_ok=True)\n",
    "        data=read_data_from_folder(folder_path)\n",
    "        print(folder_name)\n",
    "        #data.to_csv(f\"./{folder_name}/DATA.csv\",index=False)\n",
    "        #f\"./{folder_name}/DATA_100.csv\")\n",
    "        img_dir = f\"{target_folder}/{folder_name}/patches\"\n",
    "        os.makedirs(img_dir,exist_ok=True)\n",
    "\n",
    "        whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,100).to_csv(f\"./{folder_name}/DATA_100.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,200).to_csv(f\"./{folder_name}/DATA_200.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,300).to_csv(f\"./{folder_name}/DATA_300.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,400).to_csv(f\"./{folder_name}/DATA_400.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,500).to_csv(f\"./{folder_name}/DATA_500.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,1000).to_csv(f\"./{folder_name}/DATA_1000.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,1500).to_csv(f\"./{folder_name}/DATA_1500.csv\",index=False)\n",
    "        # whole_data_from_raw_data_for_lambda_meter_patch_sensor_plus_map(data,img_dir,2000).to_csv(f\"./{folder_name}/DATA_2000.csv\",index=False)\n",
    "    folder_number+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "class POI_open:\n",
    "    def __init__(self):\n",
    "        with open(\"/Users/smrlab/Desktop/TW_DP/TW_DP/Data/global_dictionary.json\") as f:\n",
    "            self.open_poi_dict=json.load(f)\n",
    "    \n",
    "    def num_of_poi_open(self,time): #time in 24hrs format\n",
    "        num_poi=0\n",
    "        for k,l in self.open_poi_dict.items():\n",
    "            for ranges in l:\n",
    "                if time>=ranges[\"open\"] and time<=ranges[\"close\"]:\n",
    "                    num_poi+=1\n",
    "        return num_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_cal=POI_open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_100=glob.glob(target_folder+\"/*/*_100.csv\")\n",
    "# files_200=glob.glob(target_folder+\"/*/*_200.csv\")\n",
    "# files_300=glob.glob(target_folder+\"/*/*_300.csv\")\n",
    "# files_400=glob.glob(target_folder+\"/*/*_400.csv\")\n",
    "# files_500=glob.glob(target_folder+\"/*/*_500.csv\")\n",
    "# files_1000=glob.glob(target_folder+\"/*/*_1000.csv\")\n",
    "# files_1500=glob.glob(target_folder+\"/*/*_1500.csv\")\n",
    "# files_2000=glob.glob(target_folder+\"/*/*_2000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(i,fname):\n",
    "    df=pd.read_csv(fname)\n",
    "    df[\"Trail_type\"]= \"2018\" if \"2018\" in fname else \"2019\"\n",
    "    df['trail_no']=i\n",
    "    #other calculations\n",
    "    df['POI_open']=df.start_time.apply(lambda e:poi_cal.num_of_poi_open(e.split()[1][:-3]))\n",
    "    df['DayOfWeek']=df.start_time.apply(lambda e:pd.to_datetime(e,format=\"%m/%d/%Y %H:%M:%S\").dayofweek)\n",
    "    df['DayOfMonth']=df.start_time.apply(lambda e:pd.to_datetime(e,format=\"%m/%d/%Y %H:%M:%S\").day)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100=pd.concat([read_file(i,f) for i,f in enumerate(files_100)],axis=0).reset_index(drop=\"index\")\n",
    "# df_200=pd.concat([read_file(i,f) for i,f in enumerate(files_200)],axis=0).reset_index(drop=\"index\")\n",
    "# df_300=pd.concat([read_file(i,f) for i,f in enumerate(files_300)],axis=0).reset_index(drop=\"index\")\n",
    "# df_400=pd.concat([read_file(i,f) for i,f in enumerate(files_400)],axis=0).reset_index(drop=\"index\")\n",
    "# df_500=pd.concat([read_file(i,f) for i,f in enumerate(files_500)],axis=0).reset_index(drop=\"index\")\n",
    "# df_1000=pd.concat([read_file(i,f) for i,f in enumerate(files_1000)],axis=0).reset_index(drop=\"index\")\n",
    "# df_1500=pd.concat([read_file(i,f) for i,f in enumerate(files_1500)],axis=0).reset_index(drop=\"index\")\n",
    "# df_2000=pd.concat([read_file(i,f) for i,f in enumerate(files_2000)],axis=0).reset_index(drop=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100.to_csv(target_folder+\"/processed_data_100.csv\",index=False)\n",
    "# df_200.to_csv(target_folder+\"/processed_data_200.csv\",index=False)\n",
    "# df_300.to_csv(target_folder+\"/processed_data_300.csv\",index=False)\n",
    "# df_400.to_csv(target_folder+\"/processed_data_400.csv\",index=False)\n",
    "# df_500.to_csv(target_folder+\"/processed_data_500.csv\",index=False)\n",
    "# df_1000.to_csv(target_folder+\"/processed_data_1000.csv\",index=False)\n",
    "# df_1500.to_csv(target_folder+\"/processed_data_1500.csv\",index=False)\n",
    "# df_2000.to_csv(target_folder+\"/processed_data_2000.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot speed vs time\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
